<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head><title>R: R Interface to Apache Spark</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">
<h1> R Interface to Apache Spark
<img class="toplogo" src="../../../doc/html/Rlogo.svg" alt="[R logo]" />
</h1>
<hr/>
<div style="text-align: center;">
<a href="../../../doc/html/packages.html"><img class="arrow" src="../../../doc/html/left.jpg" alt="[Up]" /></a>
<a href="../../../doc/html/index.html"><img class="arrow" src="../../../doc/html/up.jpg" alt="[Top]" /></a>
</div><h2>Documentation for package &lsquo;sparklyr&rsquo; version 1.7.2</h2>

<ul><li><a href="../DESCRIPTION">DESCRIPTION file</a>.</li>
</ul>

<h2>Help Pages</h2>


<p style="text-align: center;">
<a href="#A">A</a>
<a href="#C">C</a>
<a href="#D">D</a>
<a href="#E">E</a>
<a href="#F">F</a>
<a href="#G">G</a>
<a href="#H">H</a>
<a href="#I">I</a>
<a href="#J">J</a>
<a href="#L">L</a>
<a href="#M">M</a>
<a href="#N">N</a>
<a href="#P">P</a>
<a href="#R">R</a>
<a href="#S">S</a>
<a href="#T">T</a>
<a href="#U">U</a>
<a href="#misc">misc</a>
</p>


<h2><a name="A">-- A --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="ml_survival_regression_tidiers.html">augment.ml_model_aft_survival_regression</a></td>
<td>Tidying methods for Spark ML Survival Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_als_tidiers.html">augment.ml_model_als</a></td>
<td>Tidying methods for Spark ML ALS</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">augment.ml_model_bisecting_kmeans</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">augment.ml_model_decision_tree_classification</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">augment.ml_model_decision_tree_regression</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">augment.ml_model_gaussian_mixture</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">augment.ml_model_gbt_classification</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">augment.ml_model_gbt_regression</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">augment.ml_model_generalized_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_isotonic_regression_tidiers.html">augment.ml_model_isotonic_regression</a></td>
<td>Tidying methods for Spark ML Isotonic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">augment.ml_model_kmeans</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda_tidiers.html">augment.ml_model_lda</a></td>
<td>Tidying methods for Spark ML LDA models</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">augment.ml_model_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_linear_svc_tidiers.html">augment.ml_model_linear_svc</a></td>
<td>Tidying methods for Spark ML linear svc</td></tr>
<tr><td style="width: 25%;"><a href="ml_logistic_regression_tidiers.html">augment.ml_model_logistic_regression</a></td>
<td>Tidying methods for Spark ML Logistic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_multilayer_perceptron_tidiers.html">augment.ml_model_multilayer_perceptron_classification</a></td>
<td>Tidying methods for Spark ML MLP</td></tr>
<tr><td style="width: 25%;"><a href="ml_naive_bayes_tidiers.html">augment.ml_model_naive_bayes</a></td>
<td>Tidying methods for Spark ML Naive Bayes</td></tr>
<tr><td style="width: 25%;"><a href="ml_pca_tidiers.html">augment.ml_model_pca</a></td>
<td>Tidying methods for Spark ML Principal Component Analysis</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">augment.ml_model_random_forest_classification</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">augment.ml_model_random_forest_regression</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
</table>

<h2><a name="C">-- C --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="checkpoint_directory.html">checkpoint_directory</a></td>
<td>Set/Get Spark checkpoint directory</td></tr>
<tr><td style="width: 25%;"><a href="collect_from_rds.html">collect_from_rds</a></td>
<td>Collect Spark data serialized in RDS format into R</td></tr>
<tr><td style="width: 25%;"><a href="compile_package_jars.html">compile_package_jars</a></td>
<td>Compile Scala sources into a Java Archive (jar)</td></tr>
<tr><td style="width: 25%;"><a href="connection_config.html">connection_config</a></td>
<td>Read configuration values for a connection</td></tr>
<tr><td style="width: 25%;"><a href="copy_to.spark_connection.html">copy_to.spark_connection</a></td>
<td>Copy an R Data Frame to Spark</td></tr>
</table>

<h2><a name="D">-- D --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="distinct.html">distinct</a></td>
<td>Distinct</td></tr>
<tr><td style="width: 25%;"><a href="download_scalac.html">download_scalac</a></td>
<td>Downloads default Scala Compilers</td></tr>
<tr><td style="width: 25%;"><a href="dplyr_hof.html">dplyr_hof</a></td>
<td>dplyr wrappers for Apache Spark higher order functions</td></tr>
</table>

<h2><a name="E">-- E --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="ensure.html">ensure</a></td>
<td>Enforce Specific Structure for R Objects</td></tr>
</table>

<h2><a name="F">-- F --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="fill.html">fill</a></td>
<td>Fill</td></tr>
<tr><td style="width: 25%;"><a href="filter.html">filter</a></td>
<td>Filter</td></tr>
<tr><td style="width: 25%;"><a href="find_scalac.html">find_scalac</a></td>
<td>Discover the Scala Compiler</td></tr>
<tr><td style="width: 25%;"><a href="ft_binarizer.html">ft_binarizer</a></td>
<td>Feature Transformation - Binarizer (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_lsh.html">ft_bucketed_random_projection_lsh</a></td>
<td>Feature Transformation - LSH (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_bucketizer.html">ft_bucketizer</a></td>
<td>Feature Transformation - Bucketizer (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_chisq_selector.html">ft_chisq_selector</a></td>
<td>Feature Transformation - ChiSqSelector (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_count_vectorizer.html">ft_count_vectorizer</a></td>
<td>Feature Transformation - CountVectorizer (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_dct.html">ft_dct</a></td>
<td>Feature Transformation - Discrete Cosine Transform (DCT) (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_dct.html">ft_discrete_cosine_transform</a></td>
<td>Feature Transformation - Discrete Cosine Transform (DCT) (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="sql-transformer.html">ft_dplyr_transformer</a></td>
<td>Feature Transformation - SQLTransformer</td></tr>
<tr><td style="width: 25%;"><a href="ft_elementwise_product.html">ft_elementwise_product</a></td>
<td>Feature Transformation - ElementwiseProduct (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_feature_hasher.html">ft_feature_hasher</a></td>
<td>Feature Transformation - FeatureHasher (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_hashing_tf.html">ft_hashing_tf</a></td>
<td>Feature Transformation - HashingTF (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_idf.html">ft_idf</a></td>
<td>Feature Transformation - IDF (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_imputer.html">ft_imputer</a></td>
<td>Feature Transformation - Imputer (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_index_to_string.html">ft_index_to_string</a></td>
<td>Feature Transformation - IndexToString (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_interaction.html">ft_interaction</a></td>
<td>Feature Transformation - Interaction (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_lsh.html">ft_lsh</a></td>
<td>Feature Transformation - LSH (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_lsh_utils.html">ft_lsh_utils</a></td>
<td>Utility functions for LSH models</td></tr>
<tr><td style="width: 25%;"><a href="ft_max_abs_scaler.html">ft_max_abs_scaler</a></td>
<td>Feature Transformation - MaxAbsScaler (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_lsh.html">ft_minhash_lsh</a></td>
<td>Feature Transformation - LSH (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_min_max_scaler.html">ft_min_max_scaler</a></td>
<td>Feature Transformation - MinMaxScaler (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_ngram.html">ft_ngram</a></td>
<td>Feature Transformation - NGram (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_normalizer.html">ft_normalizer</a></td>
<td>Feature Transformation - Normalizer (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_one_hot_encoder.html">ft_one_hot_encoder</a></td>
<td>Feature Transformation - OneHotEncoder (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_one_hot_encoder_estimator.html">ft_one_hot_encoder_estimator</a></td>
<td>Feature Transformation - OneHotEncoderEstimator (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_pca.html">ft_pca</a></td>
<td>Feature Transformation - PCA (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_polynomial_expansion.html">ft_polynomial_expansion</a></td>
<td>Feature Transformation - PolynomialExpansion (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_quantile_discretizer.html">ft_quantile_discretizer</a></td>
<td>Feature Transformation - QuantileDiscretizer (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_regex_tokenizer.html">ft_regex_tokenizer</a></td>
<td>Feature Transformation - RegexTokenizer (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_robust_scaler.html">ft_robust_scaler</a></td>
<td>Feature Transformation - RobustScaler (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_r_formula.html">ft_r_formula</a></td>
<td>Feature Transformation - RFormula (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="sql-transformer.html">ft_sql_transformer</a></td>
<td>Feature Transformation - SQLTransformer</td></tr>
<tr><td style="width: 25%;"><a href="ft_standard_scaler.html">ft_standard_scaler</a></td>
<td>Feature Transformation - StandardScaler (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_stop_words_remover.html">ft_stop_words_remover</a></td>
<td>Feature Transformation - StopWordsRemover (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_string_indexer.html">ft_string_indexer</a></td>
<td>Feature Transformation - StringIndexer (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_string_indexer.html">ft_string_indexer_model</a></td>
<td>Feature Transformation - StringIndexer (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_tokenizer.html">ft_tokenizer</a></td>
<td>Feature Transformation - Tokenizer (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_vector_assembler.html">ft_vector_assembler</a></td>
<td>Feature Transformation - VectorAssembler (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_vector_indexer.html">ft_vector_indexer</a></td>
<td>Feature Transformation - VectorIndexer (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ft_vector_slicer.html">ft_vector_slicer</a></td>
<td>Feature Transformation - VectorSlicer (Transformer)</td></tr>
<tr><td style="width: 25%;"><a href="ft_word2vec.html">ft_word2vec</a></td>
<td>Feature Transformation - Word2Vec (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="full_join.html">full_join</a></td>
<td>Full join</td></tr>
<tr><td style="width: 25%;"><a href="join.tbl_spark.html">full_join.tbl_spark</a></td>
<td>Join Spark tbls.</td></tr>
</table>

<h2><a name="G">-- G --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="generic_call_interface.html">generic_call_interface</a></td>
<td>Generic Call Interface</td></tr>
<tr><td style="width: 25%;"><a href="get_spark_sql_catalog_implementation.html">get_spark_sql_catalog_implementation</a></td>
<td>Retrieve the Spark connection's SQL catalog implementation property</td></tr>
<tr><td style="width: 25%;"><a href="ml_survival_regression_tidiers.html">glance.ml_model_aft_survival_regression</a></td>
<td>Tidying methods for Spark ML Survival Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_als_tidiers.html">glance.ml_model_als</a></td>
<td>Tidying methods for Spark ML ALS</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">glance.ml_model_bisecting_kmeans</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">glance.ml_model_decision_tree_classification</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">glance.ml_model_decision_tree_regression</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">glance.ml_model_gaussian_mixture</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">glance.ml_model_gbt_classification</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">glance.ml_model_gbt_regression</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">glance.ml_model_generalized_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_isotonic_regression_tidiers.html">glance.ml_model_isotonic_regression</a></td>
<td>Tidying methods for Spark ML Isotonic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">glance.ml_model_kmeans</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda_tidiers.html">glance.ml_model_lda</a></td>
<td>Tidying methods for Spark ML LDA models</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">glance.ml_model_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_linear_svc_tidiers.html">glance.ml_model_linear_svc</a></td>
<td>Tidying methods for Spark ML linear svc</td></tr>
<tr><td style="width: 25%;"><a href="ml_logistic_regression_tidiers.html">glance.ml_model_logistic_regression</a></td>
<td>Tidying methods for Spark ML Logistic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_multilayer_perceptron_tidiers.html">glance.ml_model_multilayer_perceptron_classification</a></td>
<td>Tidying methods for Spark ML MLP</td></tr>
<tr><td style="width: 25%;"><a href="ml_naive_bayes_tidiers.html">glance.ml_model_naive_bayes</a></td>
<td>Tidying methods for Spark ML Naive Bayes</td></tr>
<tr><td style="width: 25%;"><a href="ml_pca_tidiers.html">glance.ml_model_pca</a></td>
<td>Tidying methods for Spark ML Principal Component Analysis</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">glance.ml_model_random_forest_classification</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">glance.ml_model_random_forest_regression</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
</table>

<h2><a name="H">-- H --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="spark-api.html">hive_context</a></td>
<td>Access the Spark API</td></tr>
<tr><td style="width: 25%;"><a href="hive_context_config.html">hive_context_config</a></td>
<td>Runtime configuration interface for Hive</td></tr>
<tr><td style="width: 25%;"><a href="hof_aggregate.html">hof_aggregate</a></td>
<td>Apply Aggregate Function to Array Column</td></tr>
<tr><td style="width: 25%;"><a href="hof_array_sort.html">hof_array_sort</a></td>
<td>Sorts array using a custom comparator</td></tr>
<tr><td style="width: 25%;"><a href="hof_exists.html">hof_exists</a></td>
<td>Determine Whether Some Element Exists in an Array Column</td></tr>
<tr><td style="width: 25%;"><a href="hof_filter.html">hof_filter</a></td>
<td>Filter Array Column</td></tr>
<tr><td style="width: 25%;"><a href="hof_forall.html">hof_forall</a></td>
<td>Checks whether all elements in an array satisfy a predicate</td></tr>
<tr><td style="width: 25%;"><a href="hof_map_filter.html">hof_map_filter</a></td>
<td>Filters a map</td></tr>
<tr><td style="width: 25%;"><a href="hof_map_zip_with.html">hof_map_zip_with</a></td>
<td>Merges two maps into one</td></tr>
<tr><td style="width: 25%;"><a href="hof_transform.html">hof_transform</a></td>
<td>Transform Array Column</td></tr>
<tr><td style="width: 25%;"><a href="hof_transform_keys.html">hof_transform_keys</a></td>
<td>Transforms keys of a map</td></tr>
<tr><td style="width: 25%;"><a href="hof_transform_values.html">hof_transform_values</a></td>
<td>Transforms values of a map</td></tr>
<tr><td style="width: 25%;"><a href="hof_zip_with.html">hof_zip_with</a></td>
<td>Combines 2 Array Columns</td></tr>
</table>

<h2><a name="I">-- I --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="inner_join.html">inner_join</a></td>
<td>Inner join</td></tr>
<tr><td style="width: 25%;"><a href="join.tbl_spark.html">inner_join.tbl_spark</a></td>
<td>Join Spark tbls.</td></tr>
<tr><td style="width: 25%;"><a href="invoke.html">invoke</a></td>
<td>Invoke a Method on a JVM Object</td></tr>
<tr><td style="width: 25%;"><a href="invoke.html">invoke_new</a></td>
<td>Invoke a Method on a JVM Object</td></tr>
<tr><td style="width: 25%;"><a href="invoke.html">invoke_static</a></td>
<td>Invoke a Method on a JVM Object</td></tr>
<tr><td style="width: 25%;"><a href="ml-transform-methods.html">is_ml_estimator</a></td>
<td>Spark ML - Transform, fit, and predict methods (ml_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="ml-transform-methods.html">is_ml_transformer</a></td>
<td>Spark ML - Transform, fit, and predict methods (ml_ interface)</td></tr>
</table>

<h2><a name="J">-- J --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="jarray.html">jarray</a></td>
<td>Instantiate a Java array with a specific element type.</td></tr>
<tr><td style="width: 25%;"><a href="spark-api.html">java_context</a></td>
<td>Access the Spark API</td></tr>
<tr><td style="width: 25%;"><a href="jfloat.html">jfloat</a></td>
<td>Instantiate a Java float type.</td></tr>
<tr><td style="width: 25%;"><a href="jfloat_array.html">jfloat_array</a></td>
<td>Instantiate an Array[Float].</td></tr>
<tr><td style="width: 25%;"><a href="join.tbl_spark.html">join.tbl_spark</a></td>
<td>Join Spark tbls.</td></tr>
<tr><td style="width: 25%;"><a href="j_invoke.html">j_invoke</a></td>
<td>Invoke a Java function.</td></tr>
<tr><td style="width: 25%;"><a href="j_invoke.html">j_invoke_new</a></td>
<td>Invoke a Java function.</td></tr>
<tr><td style="width: 25%;"><a href="j_invoke.html">j_invoke_static</a></td>
<td>Invoke a Java function.</td></tr>
</table>

<h2><a name="L">-- L --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="left_join.html">left_join</a></td>
<td>Left join</td></tr>
<tr><td style="width: 25%;"><a href="join.tbl_spark.html">left_join.tbl_spark</a></td>
<td>Join Spark tbls.</td></tr>
<tr><td style="width: 25%;"><a href="list_sparklyr_jars.html">list_sparklyr_jars</a></td>
<td>list all sparklyr-*.jar files that have been built</td></tr>
<tr><td style="width: 25%;"><a href="livy_config.html">livy_config</a></td>
<td>Create a Spark Configuration for Livy</td></tr>
<tr><td style="width: 25%;"><a href="livy_service.html">livy_service_start</a></td>
<td>Start Livy</td></tr>
<tr><td style="width: 25%;"><a href="livy_service.html">livy_service_stop</a></td>
<td>Start Livy</td></tr>
</table>

<h2><a name="M">-- M --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="ml-params.html">ml-params</a></td>
<td>Spark ML - ML Params</td></tr>
<tr><td style="width: 25%;"><a href="ml-persistence.html">ml-persistence</a></td>
<td>Spark ML - Model Persistence</td></tr>
<tr><td style="width: 25%;"><a href="ml-transform-methods.html">ml-transform-methods</a></td>
<td>Spark ML - Transform, fit, and predict methods (ml_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="ml-tuning.html">ml-tuning</a></td>
<td>Spark ML - Tuning</td></tr>
<tr><td style="width: 25%;"><a href="ml_aft_survival_regression.html">ml_aft_survival_regression</a></td>
<td>Spark ML - Survival Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_als.html">ml_als</a></td>
<td>Spark ML - ALS</td></tr>
<tr><td style="width: 25%;"><a href="ml_als_tidiers.html">ml_als_tidiers</a></td>
<td>Tidying methods for Spark ML ALS</td></tr>
<tr><td style="width: 25%;"><a href="ft_lsh_utils.html">ml_approx_nearest_neighbors</a></td>
<td>Utility functions for LSH models</td></tr>
<tr><td style="width: 25%;"><a href="ft_lsh_utils.html">ml_approx_similarity_join</a></td>
<td>Utility functions for LSH models</td></tr>
<tr><td style="width: 25%;"><a href="ml_fpgrowth.html">ml_association_rules</a></td>
<td>Frequent Pattern Mining - FPGrowth</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluator.html">ml_binary_classification_eval</a></td>
<td>Spark ML - Evaluators</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluator.html">ml_binary_classification_evaluator</a></td>
<td>Spark ML - Evaluators</td></tr>
<tr><td style="width: 25%;"><a href="ml_bisecting_kmeans.html">ml_bisecting_kmeans</a></td>
<td>Spark ML - Bisecting K-Means Clustering</td></tr>
<tr><td style="width: 25%;"><a href="ml_chisquare_test.html">ml_chisquare_test</a></td>
<td>Chi-square hypothesis testing for categorical data.</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluator.html">ml_classification_eval</a></td>
<td>Spark ML - Evaluators</td></tr>
<tr><td style="width: 25%;"><a href="ml_clustering_evaluator.html">ml_clustering_evaluator</a></td>
<td>Spark ML - Clustering Evaluator</td></tr>
<tr><td style="width: 25%;"><a href="ml_kmeans.html">ml_compute_cost</a></td>
<td>Spark ML - K-Means Clustering</td></tr>
<tr><td style="width: 25%;"><a href="ml_kmeans.html">ml_compute_silhouette_measure</a></td>
<td>Spark ML - K-Means Clustering</td></tr>
<tr><td style="width: 25%;"><a href="ml_corr.html">ml_corr</a></td>
<td>Compute correlation matrix</td></tr>
<tr><td style="width: 25%;"><a href="ml-tuning.html">ml_cross_validator</a></td>
<td>Spark ML - Tuning</td></tr>
<tr><td style="width: 25%;"><a href="ml_decision_tree.html">ml_decision_tree</a></td>
<td>Spark ML - Decision Trees</td></tr>
<tr><td style="width: 25%;"><a href="ml_decision_tree.html">ml_decision_tree_classifier</a></td>
<td>Spark ML - Decision Trees</td></tr>
<tr><td style="width: 25%;"><a href="ml_decision_tree.html">ml_decision_tree_regressor</a></td>
<td>Spark ML - Decision Trees</td></tr>
<tr><td style="width: 25%;"><a href="ml_default_stop_words.html">ml_default_stop_words</a></td>
<td>Default stop words</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda.html">ml_describe_topics</a></td>
<td>Spark ML - Latent Dirichlet Allocation</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate.ml_evaluator</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate.ml_generalized_linear_regression_model</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate.ml_linear_regression_model</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate.ml_logistic_regression_model</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate.ml_model_classification</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate.ml_model_clustering</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate.ml_model_generalized_linear_regression</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate.ml_model_linear_regression</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluate.html">ml_evaluate.ml_model_logistic_regression</a></td>
<td>Evaluate the Model on a Validation Set</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluator.html">ml_evaluator</a></td>
<td>Spark ML - Evaluators</td></tr>
<tr><td style="width: 25%;"><a href="ml_feature_importances.html">ml_feature_importances</a></td>
<td>Spark ML - Feature Importance for Tree Models</td></tr>
<tr><td style="width: 25%;"><a href="ft_word2vec.html">ml_find_synonyms</a></td>
<td>Feature Transformation - Word2Vec (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ml-transform-methods.html">ml_fit</a></td>
<td>Spark ML - Transform, fit, and predict methods (ml_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="ml-transform-methods.html">ml_fit_and_transform</a></td>
<td>Spark ML - Transform, fit, and predict methods (ml_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="ml_fpgrowth.html">ml_fpgrowth</a></td>
<td>Frequent Pattern Mining - FPGrowth</td></tr>
<tr><td style="width: 25%;"><a href="ml_fpgrowth.html">ml_freq_itemsets</a></td>
<td>Frequent Pattern Mining - FPGrowth</td></tr>
<tr><td style="width: 25%;"><a href="ml_prefixspan.html">ml_freq_seq_patterns</a></td>
<td>Frequent Pattern Mining - PrefixSpan</td></tr>
<tr><td style="width: 25%;"><a href="ml_gaussian_mixture.html">ml_gaussian_mixture</a></td>
<td>Spark ML - Gaussian Mixture clustering.</td></tr>
<tr><td style="width: 25%;"><a href="ml_gradient_boosted_trees.html">ml_gbt_classifier</a></td>
<td>Spark ML - Gradient Boosted Trees</td></tr>
<tr><td style="width: 25%;"><a href="ml_gradient_boosted_trees.html">ml_gbt_regressor</a></td>
<td>Spark ML - Gradient Boosted Trees</td></tr>
<tr><td style="width: 25%;"><a href="ml_generalized_linear_regression.html">ml_generalized_linear_regression</a></td>
<td>Spark ML - Generalized Linear Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">ml_glm_tidiers</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_gradient_boosted_trees.html">ml_gradient_boosted_trees</a></td>
<td>Spark ML - Gradient Boosted Trees</td></tr>
<tr><td style="width: 25%;"><a href="ml_isotonic_regression.html">ml_isotonic_regression</a></td>
<td>Spark ML - Isotonic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_isotonic_regression_tidiers.html">ml_isotonic_regression_tidiers</a></td>
<td>Tidying methods for Spark ML Isotonic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml-params.html">ml_is_set</a></td>
<td>Spark ML - ML Params</td></tr>
<tr><td style="width: 25%;"><a href="ml_kmeans.html">ml_kmeans</a></td>
<td>Spark ML - K-Means Clustering</td></tr>
<tr><td style="width: 25%;"><a href="ml_kmeans_cluster_eval.html">ml_kmeans_cluster_eval</a></td>
<td>Evaluate a K-mean clustering</td></tr>
<tr><td style="width: 25%;"><a href="ft_string_indexer.html">ml_labels</a></td>
<td>Feature Transformation - StringIndexer (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda.html">ml_lda</a></td>
<td>Spark ML - Latent Dirichlet Allocation</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda_tidiers.html">ml_lda_tidiers</a></td>
<td>Tidying methods for Spark ML LDA models</td></tr>
<tr><td style="width: 25%;"><a href="ml_linear_regression.html">ml_linear_regression</a></td>
<td>Spark ML - Linear Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_linear_svc.html">ml_linear_svc</a></td>
<td>Spark ML - LinearSVC</td></tr>
<tr><td style="width: 25%;"><a href="ml_linear_svc_tidiers.html">ml_linear_svc_tidiers</a></td>
<td>Tidying methods for Spark ML linear svc</td></tr>
<tr><td style="width: 25%;"><a href="ml-persistence.html">ml_load</a></td>
<td>Spark ML - Model Persistence</td></tr>
<tr><td style="width: 25%;"><a href="ml_logistic_regression.html">ml_logistic_regression</a></td>
<td>Spark ML - Logistic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_logistic_regression_tidiers.html">ml_logistic_regression_tidiers</a></td>
<td>Tidying methods for Spark ML Logistic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda.html">ml_log_likelihood</a></td>
<td>Spark ML - Latent Dirichlet Allocation</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda.html">ml_log_perplexity</a></td>
<td>Spark ML - Latent Dirichlet Allocation</td></tr>
<tr><td style="width: 25%;"><a href="ml_model_data.html">ml_model_data</a></td>
<td>Extracts data associated with a Spark ML model</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluator.html">ml_multiclass_classification_evaluator</a></td>
<td>Spark ML - Evaluators</td></tr>
<tr><td style="width: 25%;"><a href="ml_multilayer_perceptron_classifier.html">ml_multilayer_perceptron</a></td>
<td>Spark ML - Multilayer Perceptron</td></tr>
<tr><td style="width: 25%;"><a href="ml_multilayer_perceptron_classifier.html">ml_multilayer_perceptron_classifier</a></td>
<td>Spark ML - Multilayer Perceptron</td></tr>
<tr><td style="width: 25%;"><a href="ml_multilayer_perceptron_tidiers.html">ml_multilayer_perceptron_tidiers</a></td>
<td>Tidying methods for Spark ML MLP</td></tr>
<tr><td style="width: 25%;"><a href="ml_naive_bayes.html">ml_naive_bayes</a></td>
<td>Spark ML - Naive-Bayes</td></tr>
<tr><td style="width: 25%;"><a href="ml_naive_bayes_tidiers.html">ml_naive_bayes_tidiers</a></td>
<td>Tidying methods for Spark ML Naive Bayes</td></tr>
<tr><td style="width: 25%;"><a href="ml_one_vs_rest.html">ml_one_vs_rest</a></td>
<td>Spark ML - OneVsRest</td></tr>
<tr><td style="width: 25%;"><a href="ml-params.html">ml_param</a></td>
<td>Spark ML - ML Params</td></tr>
<tr><td style="width: 25%;"><a href="ml-params.html">ml_params</a></td>
<td>Spark ML - ML Params</td></tr>
<tr><td style="width: 25%;"><a href="ml-params.html">ml_param_map</a></td>
<td>Spark ML - ML Params</td></tr>
<tr><td style="width: 25%;"><a href="ft_pca.html">ml_pca</a></td>
<td>Feature Transformation - PCA (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="ml_pca_tidiers.html">ml_pca_tidiers</a></td>
<td>Tidying methods for Spark ML Principal Component Analysis</td></tr>
<tr><td style="width: 25%;"><a href="ml_pipeline.html">ml_pipeline</a></td>
<td>Spark ML - Pipelines</td></tr>
<tr><td style="width: 25%;"><a href="ml_power_iteration.html">ml_power_iteration</a></td>
<td>Spark ML - Power Iteration Clustering</td></tr>
<tr><td style="width: 25%;"><a href="ml-transform-methods.html">ml_predict</a></td>
<td>Spark ML - Transform, fit, and predict methods (ml_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="ml-transform-methods.html">ml_predict.ml_model_classification</a></td>
<td>Spark ML - Transform, fit, and predict methods (ml_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="ml_prefixspan.html">ml_prefixspan</a></td>
<td>Frequent Pattern Mining - PrefixSpan</td></tr>
<tr><td style="width: 25%;"><a href="ml_random_forest.html">ml_random_forest</a></td>
<td>Spark ML - Random Forest</td></tr>
<tr><td style="width: 25%;"><a href="ml_random_forest.html">ml_random_forest_classifier</a></td>
<td>Spark ML - Random Forest</td></tr>
<tr><td style="width: 25%;"><a href="ml_random_forest.html">ml_random_forest_regressor</a></td>
<td>Spark ML - Random Forest</td></tr>
<tr><td style="width: 25%;"><a href="ml_als.html">ml_recommend</a></td>
<td>Spark ML - ALS</td></tr>
<tr><td style="width: 25%;"><a href="ml_evaluator.html">ml_regression_evaluator</a></td>
<td>Spark ML - Evaluators</td></tr>
<tr><td style="width: 25%;"><a href="ml-persistence.html">ml_save</a></td>
<td>Spark ML - Model Persistence</td></tr>
<tr><td style="width: 25%;"><a href="ml-persistence.html">ml_save.ml_model</a></td>
<td>Spark ML - Model Persistence</td></tr>
<tr><td style="width: 25%;"><a href="ml_stage.html">ml_stage</a></td>
<td>Spark ML - Pipeline stage extraction</td></tr>
<tr><td style="width: 25%;"><a href="ml_stage.html">ml_stages</a></td>
<td>Spark ML - Pipeline stage extraction</td></tr>
<tr><td style="width: 25%;"><a href="ml-tuning.html">ml_sub_models</a></td>
<td>Spark ML - Tuning</td></tr>
<tr><td style="width: 25%;"><a href="ml_summary.html">ml_summary</a></td>
<td>Spark ML - Extraction of summary metrics</td></tr>
<tr><td style="width: 25%;"><a href="ml_aft_survival_regression.html">ml_survival_regression</a></td>
<td>Spark ML - Survival Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_survival_regression_tidiers.html">ml_survival_regression_tidiers</a></td>
<td>Tidying methods for Spark ML Survival Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda.html">ml_topics_matrix</a></td>
<td>Spark ML - Latent Dirichlet Allocation</td></tr>
<tr><td style="width: 25%;"><a href="ml-tuning.html">ml_train_validation_split</a></td>
<td>Spark ML - Tuning</td></tr>
<tr><td style="width: 25%;"><a href="ml-transform-methods.html">ml_transform</a></td>
<td>Spark ML - Transform, fit, and predict methods (ml_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="ml_feature_importances.html">ml_tree_feature_importance</a></td>
<td>Spark ML - Feature Importance for Tree Models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">ml_tree_tidiers</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_uid.html">ml_uid</a></td>
<td>Spark ML - UID</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">ml_unsupervised_tidiers</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml-tuning.html">ml_validation_metrics</a></td>
<td>Spark ML - Tuning</td></tr>
<tr><td style="width: 25%;"><a href="ft_count_vectorizer.html">ml_vocabulary</a></td>
<td>Feature Transformation - CountVectorizer (Estimator)</td></tr>
<tr><td style="width: 25%;"><a href="mutate.html">mutate</a></td>
<td>Mutate</td></tr>
</table>

<h2><a name="N">-- N --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="na.replace.html">na.replace</a></td>
<td>Replace Missing Values in Objects</td></tr>
<tr><td style="width: 25%;"><a href="nest.html">nest</a></td>
<td>Nest</td></tr>
</table>

<h2><a name="P">-- P --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="pivot_longer.html">pivot_longer</a></td>
<td>Pivot longer</td></tr>
<tr><td style="width: 25%;"><a href="pivot_wider.html">pivot_wider</a></td>
<td>Pivot wider</td></tr>
</table>

<h2><a name="R">-- R --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="random_string.html">random_string</a></td>
<td>Random string generation</td></tr>
<tr><td style="width: 25%;"><a href="reactiveSpark.html">reactiveSpark</a></td>
<td>Reactive spark reader</td></tr>
<tr><td style="width: 25%;"><a href="registerDoSpark.html">registerDoSpark</a></td>
<td>Register a Parallel Backend</td></tr>
<tr><td style="width: 25%;"><a href="register_extension.html">registered_extensions</a></td>
<td>Register a Package that Implements a Spark Extension</td></tr>
<tr><td style="width: 25%;"><a href="register_extension.html">register_extension</a></td>
<td>Register a Package that Implements a Spark Extension</td></tr>
<tr><td style="width: 25%;"><a href="replace_na.html">replace_na</a></td>
<td>Replace NA</td></tr>
<tr><td style="width: 25%;"><a href="right_join.html">right_join</a></td>
<td>Right join</td></tr>
<tr><td style="width: 25%;"><a href="join.tbl_spark.html">right_join.tbl_spark</a></td>
<td>Join Spark tbls.</td></tr>
</table>

<h2><a name="S">-- S --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf-saveload</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf-transform-methods.html">sdf-transform-methods</a></td>
<td>Spark ML - Transform, fit, and predict methods (sdf_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="sdf_along.html">sdf_along</a></td>
<td>Create DataFrame for along Object</td></tr>
<tr><td style="width: 25%;"><a href="sdf_bind.html">sdf_bind</a></td>
<td>Bind multiple Spark DataFrames by row and column</td></tr>
<tr><td style="width: 25%;"><a href="sdf_bind.html">sdf_bind_cols</a></td>
<td>Bind multiple Spark DataFrames by row and column</td></tr>
<tr><td style="width: 25%;"><a href="sdf_bind.html">sdf_bind_rows</a></td>
<td>Bind multiple Spark DataFrames by row and column</td></tr>
<tr><td style="width: 25%;"><a href="sdf_broadcast.html">sdf_broadcast</a></td>
<td>Broadcast hint</td></tr>
<tr><td style="width: 25%;"><a href="sdf_checkpoint.html">sdf_checkpoint</a></td>
<td>Checkpoint a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_coalesce.html">sdf_coalesce</a></td>
<td>Coalesces a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_collect.html">sdf_collect</a></td>
<td>Collect a Spark DataFrame into R.</td></tr>
<tr><td style="width: 25%;"><a href="sdf_copy_to.html">sdf_copy_to</a></td>
<td>Copy an Object into Spark</td></tr>
<tr><td style="width: 25%;"><a href="sdf_crosstab.html">sdf_crosstab</a></td>
<td>Cross Tabulation</td></tr>
<tr><td style="width: 25%;"><a href="sdf_debug_string.html">sdf_debug_string</a></td>
<td>Debug Info for Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_describe.html">sdf_describe</a></td>
<td>Compute summary statistics for columns of a data frame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_dim.html">sdf_dim</a></td>
<td>Support for Dimension Operations</td></tr>
<tr><td style="width: 25%;"><a href="sdf_distinct.html">sdf_distinct</a></td>
<td>Invoke distinct on a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_drop_duplicates.html">sdf_drop_duplicates</a></td>
<td>Remove duplicates from a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_expand_grid.html">sdf_expand_grid</a></td>
<td>Create a Spark dataframe containing all combinations of inputs</td></tr>
<tr><td style="width: 25%;"><a href="sdf-transform-methods.html">sdf_fit</a></td>
<td>Spark ML - Transform, fit, and predict methods (sdf_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="sdf-transform-methods.html">sdf_fit_and_transform</a></td>
<td>Spark ML - Transform, fit, and predict methods (sdf_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="sdf_from_avro.html">sdf_from_avro</a></td>
<td>Convert column(s) from avro format</td></tr>
<tr><td style="width: 25%;"><a href="sdf_copy_to.html">sdf_import</a></td>
<td>Copy an Object into Spark</td></tr>
<tr><td style="width: 25%;"><a href="sdf_is_streaming.html">sdf_is_streaming</a></td>
<td>Spark DataFrame is Streaming</td></tr>
<tr><td style="width: 25%;"><a href="sdf_last_index.html">sdf_last_index</a></td>
<td>Returns the last index of a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_len.html">sdf_len</a></td>
<td>Create DataFrame for Length</td></tr>
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf_load_parquet</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf_load_table</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_dim.html">sdf_ncol</a></td>
<td>Support for Dimension Operations</td></tr>
<tr><td style="width: 25%;"><a href="sdf_dim.html">sdf_nrow</a></td>
<td>Support for Dimension Operations</td></tr>
<tr><td style="width: 25%;"><a href="sdf_num_partitions.html">sdf_num_partitions</a></td>
<td>Gets number of partitions of a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_random_split.html">sdf_partition</a></td>
<td>Partition a Spark Dataframe</td></tr>
<tr><td style="width: 25%;"><a href="sdf_partition_sizes.html">sdf_partition_sizes</a></td>
<td>Compute the number of records within each partition of a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_persist.html">sdf_persist</a></td>
<td>Persist a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_pivot.html">sdf_pivot</a></td>
<td>Pivot a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf-transform-methods.html">sdf_predict</a></td>
<td>Spark ML - Transform, fit, and predict methods (sdf_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="sdf_project.html">sdf_project</a></td>
<td>Project features onto principal components</td></tr>
<tr><td style="width: 25%;"><a href="sdf_quantile.html">sdf_quantile</a></td>
<td>Compute (Approximate) Quantiles with a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_random_split.html">sdf_random_split</a></td>
<td>Partition a Spark Dataframe</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rbeta.html">sdf_rbeta</a></td>
<td>Generate random samples from a Beta distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rbinom.html">sdf_rbinom</a></td>
<td>Generate random samples from a binomial distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rcauchy.html">sdf_rcauchy</a></td>
<td>Generate random samples from a Cauchy distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rchisq.html">sdf_rchisq</a></td>
<td>Generate random samples from a chi-squared distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_read_column.html">sdf_read_column</a></td>
<td>Read a Column from a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_register.html">sdf_register</a></td>
<td>Register a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_repartition.html">sdf_repartition</a></td>
<td>Repartition a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_residuals.html">sdf_residuals</a></td>
<td>Model Residuals</td></tr>
<tr><td style="width: 25%;"><a href="sdf_residuals.html">sdf_residuals.ml_model_generalized_linear_regression</a></td>
<td>Model Residuals</td></tr>
<tr><td style="width: 25%;"><a href="sdf_residuals.html">sdf_residuals.ml_model_linear_regression</a></td>
<td>Model Residuals</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rexp.html">sdf_rexp</a></td>
<td>Generate random samples from an exponential distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rgamma.html">sdf_rgamma</a></td>
<td>Generate random samples from a Gamma distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rgeom.html">sdf_rgeom</a></td>
<td>Generate random samples from a geometric distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rhyper.html">sdf_rhyper</a></td>
<td>Generate random samples from a hypergeometric distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rlnorm.html">sdf_rlnorm</a></td>
<td>Generate random samples from a log normal distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rnorm.html">sdf_rnorm</a></td>
<td>Generate random samples from the standard normal distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rpois.html">sdf_rpois</a></td>
<td>Generate random samples from a Poisson distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rt.html">sdf_rt</a></td>
<td>Generate random samples from a t-distribution</td></tr>
<tr><td style="width: 25%;"><a href="sdf_runif.html">sdf_runif</a></td>
<td>Generate random samples from the uniform distribution U(0, 1).</td></tr>
<tr><td style="width: 25%;"><a href="sdf_rweibull.html">sdf_rweibull</a></td>
<td>Generate random samples from a Weibull distribution.</td></tr>
<tr><td style="width: 25%;"><a href="sdf_sample.html">sdf_sample</a></td>
<td>Randomly Sample Rows from a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf_save_parquet</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf-saveload.html">sdf_save_table</a></td>
<td>Save / Load a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_schema.html">sdf_schema</a></td>
<td>Read the Schema of a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_separate_column.html">sdf_separate_column</a></td>
<td>Separate a Vector Column into Scalar Columns</td></tr>
<tr><td style="width: 25%;"><a href="sdf_seq.html">sdf_seq</a></td>
<td>Create DataFrame for Range</td></tr>
<tr><td style="width: 25%;"><a href="sdf_sort.html">sdf_sort</a></td>
<td>Sort a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_sql.html">sdf_sql</a></td>
<td>Spark DataFrame from SQL</td></tr>
<tr><td style="width: 25%;"><a href="sdf_to_avro.html">sdf_to_avro</a></td>
<td>Convert column(s) to avro format</td></tr>
<tr><td style="width: 25%;"><a href="sdf-transform-methods.html">sdf_transform</a></td>
<td>Spark ML - Transform, fit, and predict methods (sdf_ interface)</td></tr>
<tr><td style="width: 25%;"><a href="sdf_unnest_longer.html">sdf_unnest_longer</a></td>
<td>Unnest longer</td></tr>
<tr><td style="width: 25%;"><a href="sdf_unnest_wider.html">sdf_unnest_wider</a></td>
<td>Unnest wider</td></tr>
<tr><td style="width: 25%;"><a href="sdf_weighted_sample.html">sdf_weighted_sample</a></td>
<td>Perform Weighted Random Sampling on a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_with_sequential_id.html">sdf_with_sequential_id</a></td>
<td>Add a Sequential ID Column to a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="sdf_with_unique_id.html">sdf_with_unique_id</a></td>
<td>Add a Unique ID Column to a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="select.html">select</a></td>
<td>Select</td></tr>
<tr><td style="width: 25%;"><a href="separate.html">separate</a></td>
<td>Separate</td></tr>
<tr><td style="width: 25%;"><a href="spark-api.html">spark-api</a></td>
<td>Access the Spark API</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark-connections</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark_adaptive_query_execution.html">spark_adaptive_query_execution</a></td>
<td>Retrieves or sets status of Spark AQE</td></tr>
<tr><td style="width: 25%;"><a href="spark_advisory_shuffle_partition_size.html">spark_advisory_shuffle_partition_size</a></td>
<td>Retrieves or sets advisory size of the shuffle partition</td></tr>
<tr><td style="width: 25%;"><a href="spark_apply.html">spark_apply</a></td>
<td>Apply an R Function in Spark</td></tr>
<tr><td style="width: 25%;"><a href="spark_apply_bundle.html">spark_apply_bundle</a></td>
<td>Create Bundle for Spark Apply</td></tr>
<tr><td style="width: 25%;"><a href="spark_apply_log.html">spark_apply_log</a></td>
<td>Log Writer for Spark Apply</td></tr>
<tr><td style="width: 25%;"><a href="spark_auto_broadcast_join_threshold.html">spark_auto_broadcast_join_threshold</a></td>
<td>Retrieves or sets the auto broadcast join threshold</td></tr>
<tr><td style="width: 25%;"><a href="spark_install.html">spark_available_versions</a></td>
<td>Download and install various versions of Spark</td></tr>
<tr><td style="width: 25%;"><a href="spark_coalesce_initial_num_partitions.html">spark_coalesce_initial_num_partitions</a></td>
<td>Retrieves or sets initial number of shuffle partitions before coalescing</td></tr>
<tr><td style="width: 25%;"><a href="spark_coalesce_min_num_partitions.html">spark_coalesce_min_num_partitions</a></td>
<td>Retrieves or sets the minimum number of shuffle partitions after coalescing</td></tr>
<tr><td style="width: 25%;"><a href="spark_coalesce_shuffle_partitions.html">spark_coalesce_shuffle_partitions</a></td>
<td>Retrieves or sets whether coalescing contiguous shuffle partitions is enabled</td></tr>
<tr><td style="width: 25%;"><a href="spark_compilation_spec.html">spark_compilation_spec</a></td>
<td>Define a Spark Compilation Specification</td></tr>
<tr><td style="width: 25%;"><a href="spark_config.html">spark_config</a></td>
<td>Read Spark Configuration</td></tr>
<tr><td style="width: 25%;"><a href="spark_config_kubernetes.html">spark_config_kubernetes</a></td>
<td>Kubernetes Configuration</td></tr>
<tr><td style="width: 25%;"><a href="spark_config_packages.html">spark_config_packages</a></td>
<td>Creates Spark Configuration</td></tr>
<tr><td style="width: 25%;"><a href="spark_config_settings.html">spark_config_settings</a></td>
<td>Retrieve Available Settings</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark_connect</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark_connection.html">spark_connection</a></td>
<td>Retrieve the Spark Connection Associated with an R Object</td></tr>
<tr><td style="width: 25%;"><a href="spark_connection-class.html">spark_connection-class</a></td>
<td>spark_connection class</td></tr>
<tr><td style="width: 25%;"><a href="spark_connection_find.html">spark_connection_find</a></td>
<td>Find Spark Connection</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark_connection_is_open</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark-api.html">spark_context</a></td>
<td>Access the Spark API</td></tr>
<tr><td style="width: 25%;"><a href="spark_context_config.html">spark_context_config</a></td>
<td>Runtime configuration interface for the Spark Context.</td></tr>
<tr><td style="width: 25%;"><a href="spark_dataframe.html">spark_dataframe</a></td>
<td>Retrieve a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_default_compilation_spec.html">spark_default_compilation_spec</a></td>
<td>Default Compilation Specification for Spark Extensions</td></tr>
<tr><td style="width: 25%;"><a href="spark_dependency.html">spark_dependency</a></td>
<td>Define a Spark dependency</td></tr>
<tr><td style="width: 25%;"><a href="spark_dependency_fallback.html">spark_dependency_fallback</a></td>
<td>Fallback to Spark Dependency</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark_disconnect</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark_disconnect_all</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark_extension.html">spark_extension</a></td>
<td>Create Spark Extension</td></tr>
<tr><td style="width: 25%;"><a href="checkpoint_directory.html">spark_get_checkpoint_dir</a></td>
<td>Set/Get Spark checkpoint directory</td></tr>
<tr><td style="width: 25%;"><a href="spark_home_set.html">spark_home_set</a></td>
<td>Set the SPARK_HOME environment variable</td></tr>
<tr><td style="width: 25%;"><a href="spark_install.html">spark_install</a></td>
<td>Download and install various versions of Spark</td></tr>
<tr><td style="width: 25%;"><a href="spark_install.html">spark_installed_versions</a></td>
<td>Download and install various versions of Spark</td></tr>
<tr><td style="width: 25%;"><a href="spark_install.html">spark_install_dir</a></td>
<td>Download and install various versions of Spark</td></tr>
<tr><td style="width: 25%;"><a href="spark_install.html">spark_install_tar</a></td>
<td>Download and install various versions of Spark</td></tr>
<tr><td style="width: 25%;"><a href="spark_jobj.html">spark_jobj</a></td>
<td>Retrieve a Spark JVM Object Reference</td></tr>
<tr><td style="width: 25%;"><a href="spark_jobj-class.html">spark_jobj-class</a></td>
<td>spark_jobj class</td></tr>
<tr><td style="width: 25%;"><a href="spark_load_table.html">spark_load_table</a></td>
<td>Reads from a Spark Table into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_log.html">spark_log</a></td>
<td>View Entries in the Spark Log</td></tr>
<tr><td style="width: 25%;"><a href="spark_read.html">spark_read</a></td>
<td>Read file(s) into a Spark DataFrame using a custom reader</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_avro.html">spark_read_avro</a></td>
<td>Read Apache Avro data into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_binary.html">spark_read_binary</a></td>
<td>Read binary data into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_csv.html">spark_read_csv</a></td>
<td>Read a CSV file into a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_delta.html">spark_read_delta</a></td>
<td>Read from Delta Lake into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_image.html">spark_read_image</a></td>
<td>Read image data into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_jdbc.html">spark_read_jdbc</a></td>
<td>Read from JDBC connection into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_json.html">spark_read_json</a></td>
<td>Read a JSON file into a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_libsvm.html">spark_read_libsvm</a></td>
<td>Read libsvm file into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_orc.html">spark_read_orc</a></td>
<td>Read a ORC file into a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_parquet.html">spark_read_parquet</a></td>
<td>Read a Parquet file into a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_source.html">spark_read_source</a></td>
<td>Read from a generic source into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_table.html">spark_read_table</a></td>
<td>Reads from a Spark Table into a Spark DataFrame.</td></tr>
<tr><td style="width: 25%;"><a href="spark_read_text.html">spark_read_text</a></td>
<td>Read a Text file into a Spark DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="spark_save_table.html">spark_save_table</a></td>
<td>Saves a Spark DataFrame as a Spark table</td></tr>
<tr><td style="width: 25%;"><a href="spark-api.html">spark_session</a></td>
<td>Access the Spark API</td></tr>
<tr><td style="width: 25%;"><a href="spark_configuration.html">spark_session_config</a></td>
<td>Runtime configuration interface for the Spark Session</td></tr>
<tr><td style="width: 25%;"><a href="checkpoint_directory.html">spark_set_checkpoint_dir</a></td>
<td>Set/Get Spark checkpoint directory</td></tr>
<tr><td style="width: 25%;"><a href="spark_statistical_routines.html">spark_statistical_routines</a></td>
<td>Generate random samples from some distribution</td></tr>
<tr><td style="width: 25%;"><a href="spark-connections.html">spark_submit</a></td>
<td>Manage Spark Connections</td></tr>
<tr><td style="width: 25%;"><a href="spark_table_name.html">spark_table_name</a></td>
<td>Generate a Table Name from Expression</td></tr>
<tr><td style="width: 25%;"><a href="spark_install.html">spark_uninstall</a></td>
<td>Download and install various versions of Spark</td></tr>
<tr><td style="width: 25%;"><a href="spark_version.html">spark_version</a></td>
<td>Get the Spark Version Associated with a Spark Connection</td></tr>
<tr><td style="width: 25%;"><a href="spark_version_from_home.html">spark_version_from_home</a></td>
<td>Get the Spark Version Associated with a Spark Installation</td></tr>
<tr><td style="width: 25%;"><a href="spark_web.html">spark_web</a></td>
<td>Open the Spark web interface</td></tr>
<tr><td style="width: 25%;"><a href="spark_write.html">spark_write</a></td>
<td>Write Spark DataFrame to file using a custom writer</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_avro.html">spark_write_avro</a></td>
<td>Serialize a Spark DataFrame into Apache Avro format</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_csv.html">spark_write_csv</a></td>
<td>Write a Spark DataFrame to a CSV</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_delta.html">spark_write_delta</a></td>
<td>Writes a Spark DataFrame into Delta Lake</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_jdbc.html">spark_write_jdbc</a></td>
<td>Writes a Spark DataFrame into a JDBC table</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_json.html">spark_write_json</a></td>
<td>Write a Spark DataFrame to a JSON file</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_orc.html">spark_write_orc</a></td>
<td>Write a Spark DataFrame to a ORC file</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_parquet.html">spark_write_parquet</a></td>
<td>Write a Spark DataFrame to a Parquet file</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_rds.html">spark_write_rds</a></td>
<td>Write Spark DataFrame to RDS files</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_source.html">spark_write_source</a></td>
<td>Writes a Spark DataFrame into a generic source</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_table.html">spark_write_table</a></td>
<td>Writes a Spark DataFrame into a Spark table</td></tr>
<tr><td style="width: 25%;"><a href="spark_write_text.html">spark_write_text</a></td>
<td>Write a Spark DataFrame to a Text file</td></tr>
<tr><td style="width: 25%;"><a href="src_databases.html">src_databases</a></td>
<td>Show database list</td></tr>
<tr><td style="width: 25%;"><a href="stream_find.html">stream_find</a></td>
<td>Find Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_generate_test.html">stream_generate_test</a></td>
<td>Generate Test Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_id.html">stream_id</a></td>
<td>Spark Stream's Identifier</td></tr>
<tr><td style="width: 25%;"><a href="stream_lag.html">stream_lag</a></td>
<td>Apply lag function to columns of a Spark Streaming DataFrame</td></tr>
<tr><td style="width: 25%;"><a href="stream_name.html">stream_name</a></td>
<td>Spark Stream's Name</td></tr>
<tr><td style="width: 25%;"><a href="stream_read_csv.html">stream_read_csv</a></td>
<td>Read CSV Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_read_delta.html">stream_read_delta</a></td>
<td>Read Delta Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_read_json.html">stream_read_json</a></td>
<td>Read JSON Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_read_kafka.html">stream_read_kafka</a></td>
<td>Read Kafka Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_read_orc.html">stream_read_orc</a></td>
<td>Read ORC Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_read_parquet.html">stream_read_parquet</a></td>
<td>Read Parquet Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_read_socket.html">stream_read_socket</a></td>
<td>Read Socket Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_read_text.html">stream_read_text</a></td>
<td>Read Text Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_render.html">stream_render</a></td>
<td>Render Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_stats.html">stream_stats</a></td>
<td>Stream Statistics</td></tr>
<tr><td style="width: 25%;"><a href="stream_stop.html">stream_stop</a></td>
<td>Stops a Spark Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_trigger_continuous.html">stream_trigger_continuous</a></td>
<td>Spark Stream Continuous Trigger</td></tr>
<tr><td style="width: 25%;"><a href="stream_trigger_interval.html">stream_trigger_interval</a></td>
<td>Spark Stream Interval Trigger</td></tr>
<tr><td style="width: 25%;"><a href="stream_view.html">stream_view</a></td>
<td>View Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_watermark.html">stream_watermark</a></td>
<td>Watermark Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_write_console.html">stream_write_console</a></td>
<td>Write Console Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_write_csv.html">stream_write_csv</a></td>
<td>Write CSV Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_write_delta.html">stream_write_delta</a></td>
<td>Write Delta Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_write_json.html">stream_write_json</a></td>
<td>Write JSON Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_write_kafka.html">stream_write_kafka</a></td>
<td>Write Kafka Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_write_memory.html">stream_write_memory</a></td>
<td>Write Memory Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_write_orc.html">stream_write_orc</a></td>
<td>Write a ORC Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_write_parquet.html">stream_write_parquet</a></td>
<td>Write Parquet Stream</td></tr>
<tr><td style="width: 25%;"><a href="stream_write_text.html">stream_write_text</a></td>
<td>Write Text Stream</td></tr>
</table>

<h2><a name="T">-- T --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="tbl_cache.html">tbl_cache</a></td>
<td>Cache a Spark Table</td></tr>
<tr><td style="width: 25%;"><a href="tbl_change_db.html">tbl_change_db</a></td>
<td>Use specific database</td></tr>
<tr><td style="width: 25%;"><a href="tbl_uncache.html">tbl_uncache</a></td>
<td>Uncache a Spark Table</td></tr>
<tr><td style="width: 25%;"><a href="ml_survival_regression_tidiers.html">tidy.ml_model_aft_survival_regression</a></td>
<td>Tidying methods for Spark ML Survival Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_als_tidiers.html">tidy.ml_model_als</a></td>
<td>Tidying methods for Spark ML ALS</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">tidy.ml_model_bisecting_kmeans</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">tidy.ml_model_decision_tree_classification</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">tidy.ml_model_decision_tree_regression</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">tidy.ml_model_gaussian_mixture</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">tidy.ml_model_gbt_classification</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">tidy.ml_model_gbt_regression</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">tidy.ml_model_generalized_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_isotonic_regression_tidiers.html">tidy.ml_model_isotonic_regression</a></td>
<td>Tidying methods for Spark ML Isotonic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_unsupervised_tidiers.html">tidy.ml_model_kmeans</a></td>
<td>Tidying methods for Spark ML unsupervised models</td></tr>
<tr><td style="width: 25%;"><a href="ml_lda_tidiers.html">tidy.ml_model_lda</a></td>
<td>Tidying methods for Spark ML LDA models</td></tr>
<tr><td style="width: 25%;"><a href="ml_glm_tidiers.html">tidy.ml_model_linear_regression</a></td>
<td>Tidying methods for Spark ML linear models</td></tr>
<tr><td style="width: 25%;"><a href="ml_linear_svc_tidiers.html">tidy.ml_model_linear_svc</a></td>
<td>Tidying methods for Spark ML linear svc</td></tr>
<tr><td style="width: 25%;"><a href="ml_logistic_regression_tidiers.html">tidy.ml_model_logistic_regression</a></td>
<td>Tidying methods for Spark ML Logistic Regression</td></tr>
<tr><td style="width: 25%;"><a href="ml_multilayer_perceptron_tidiers.html">tidy.ml_model_multilayer_perceptron_classification</a></td>
<td>Tidying methods for Spark ML MLP</td></tr>
<tr><td style="width: 25%;"><a href="ml_naive_bayes_tidiers.html">tidy.ml_model_naive_bayes</a></td>
<td>Tidying methods for Spark ML Naive Bayes</td></tr>
<tr><td style="width: 25%;"><a href="ml_pca_tidiers.html">tidy.ml_model_pca</a></td>
<td>Tidying methods for Spark ML Principal Component Analysis</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">tidy.ml_model_random_forest_classification</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="ml_tree_tidiers.html">tidy.ml_model_random_forest_regression</a></td>
<td>Tidying methods for Spark ML tree models</td></tr>
<tr><td style="width: 25%;"><a href="transform_sdf.html">transform_sdf</a></td>
<td>transform a subset of column(s) in a Spark Dataframe</td></tr>
</table>

<h2><a name="U">-- U --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="unite.html">unite</a></td>
<td>Unite</td></tr>
<tr><td style="width: 25%;"><a href="unnest.html">unnest</a></td>
<td>Unnest</td></tr>
</table>

<h2><a name="misc">-- misc --</a></h2>

<table width="100%">
<tr><td style="width: 25%;"><a href="grapes-greater-than-grapes.html">%-&gt;%</a></td>
<td>Infix operator for composing a lambda expression</td></tr>
<tr><td style="width: 25%;"><a href="sub-.tbl_spark.html">[.tbl_spark</a></td>
<td>Subsetting operator for Spark dataframe</td></tr>
</table>
</div></body></html>
