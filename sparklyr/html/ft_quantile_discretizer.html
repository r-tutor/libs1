<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Feature Transformation - QuantileDiscretizer (Estimator)</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for ft_quantile_discretizer {sparklyr}"><tr><td>ft_quantile_discretizer {sparklyr}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Feature Transformation &ndash; QuantileDiscretizer (Estimator)</h2>

<h3>Description</h3>

<p><code>ft_quantile_discretizer</code> takes a column with continuous features and outputs
a column with binned categorical features. The number of bins can be
set using the <code>num_buckets</code> parameter. It is possible that the number
of buckets used will be smaller than this value, for example, if there
are too few distinct values of the input to create enough distinct
quantiles.
</p>


<h3>Usage</h3>

<pre>
ft_quantile_discretizer(x, input_col = NULL, output_col = NULL,
  num_buckets = 2L, input_cols = NULL, output_cols = NULL,
  num_buckets_array = NULL, handle_invalid = "error",
  relative_error = 0.001, dataset = NULL,
  uid = random_string("quantile_discretizer_"), ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x</code></td>
<td>
<p>A <code>spark_connection</code>, <code>ml_pipeline</code>, or a <code>tbl_spark</code>.</p>
</td></tr>
<tr valign="top"><td><code>input_col</code></td>
<td>
<p>The name of the input column.</p>
</td></tr>
<tr valign="top"><td><code>output_col</code></td>
<td>
<p>The name of the output column.</p>
</td></tr>
<tr valign="top"><td><code>num_buckets</code></td>
<td>
<p>Number of buckets (quantiles, or categories) into which data
points are grouped. Must be greater than or equal to 2.</p>
</td></tr>
<tr valign="top"><td><code>input_cols</code></td>
<td>
<p>Names of input columns.</p>
</td></tr>
<tr valign="top"><td><code>output_cols</code></td>
<td>
<p>Names of output columns.</p>
</td></tr>
<tr valign="top"><td><code>num_buckets_array</code></td>
<td>
<p>Array of number of buckets (quantiles, or categories)
into which data points are grouped. Each value must be greater than or equal to 2.</p>
</td></tr>
<tr valign="top"><td><code>handle_invalid</code></td>
<td>
<p>(Spark 2.1.0+) Param for how to handle invalid entries. Options are
'skip' (filter out rows with invalid values), 'error' (throw an error), or
'keep' (keep invalid values in a special additional bucket). Default: &quot;error&quot;</p>
</td></tr>
<tr valign="top"><td><code>relative_error</code></td>
<td>
<p>(Spark 2.0.0+) Relative error (see documentation for
org.apache.spark.sql.DataFrameStatFunctions.approxQuantile
<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameStatFunctions">here</a>
for description). Must be in the range [0, 1]. default: 0.001</p>
</td></tr>
<tr valign="top"><td><code>dataset</code></td>
<td>
<p>(Optional) A <code>tbl_spark</code>. If provided, eagerly fit the (estimator)
feature &quot;transformer&quot; against <code>dataset</code>. See details.</p>
</td></tr>
<tr valign="top"><td><code>uid</code></td>
<td>
<p>A character string used to uniquely identify the feature transformer.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Optional arguments; currently unused.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>NaN handling: null and NaN values will be ignored from the column
during <code>QuantileDiscretizer</code> fitting. This will produce a <code>Bucketizer</code>
model for making predictions. During the transformation, <code>Bucketizer</code>
will raise an error when it finds NaN values in the dataset, but the
user can also choose to either keep or remove NaN values within the
dataset by setting <code>handle_invalid</code> If the user chooses to keep NaN values,
they will be handled specially and placed into their own bucket,
for example, if 4 buckets are used, then non-NaN data will be put
into buckets[0-3], but NaNs will be counted in a special bucket[4].
</p>
<p>Algorithm: The bin ranges are chosen using an approximate algorithm (see
the documentation for org.apache.spark.sql.DataFrameStatFunctions.approxQuantile
<a href="https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameStatFunctions">here</a> for a detailed description). The precision of the approximation can be
controlled with the <code>relative_error</code> parameter. The lower and upper bin
bounds will be -Infinity and +Infinity, covering all real values.
</p>
<p>Note that the result may be different every time you run it, since the sample
strategy behind it is non-deterministic.
</p>
<p>When <code>dataset</code> is provided for an estimator transformer, the function
internally calls <code>ml_fit()</code> against <code>dataset</code>. Hence, the methods for
<code>spark_connection</code> and <code>ml_pipeline</code> will then return a <code>ml_transformer</code>
and a <code>ml_pipeline</code> with a <code>ml_transformer</code> appended, respectively. When
<code>x</code> is a <code>tbl_spark</code>, the estimator will be fit against <code>dataset</code> before
transforming <code>x</code>.
</p>
<p>When <code>dataset</code> is not specified, the constructor returns a <code>ml_estimator</code>, and,
in the case where <code>x</code> is a <code>tbl_spark</code>, the estimator fits against <code>x</code> then
to obtain a transformer, which is then immediately used to transform <code>x</code>.
</p>


<h3>Value</h3>

<p>The object returned depends on the class of <code>x</code>.
</p>

<ul>
<li> <p><code>spark_connection</code>: When <code>x</code> is a <code>spark_connection</code>, the function returns a <code>ml_transformer</code>,
a <code>ml_estimator</code>, or one of their subclasses. The object contains a pointer to
a Spark <code>Transformer</code> or <code>Estimator</code> object and can be used to compose
<code>Pipeline</code> objects.
</p>
</li>
<li> <p><code>ml_pipeline</code>: When <code>x</code> is a <code>ml_pipeline</code>, the function returns a <code>ml_pipeline</code> with
the transformer or estimator appended to the pipeline.
</p>
</li>
<li> <p><code>tbl_spark</code>: When <code>x</code> is a <code>tbl_spark</code>, a transformer is constructed then
immediately applied to the input <code>tbl_spark</code>, returning a <code>tbl_spark</code>
</p>
</li></ul>



<h3>See Also</h3>

<p>See <a href="http://spark.apache.org/docs/latest/ml-features.html">http://spark.apache.org/docs/latest/ml-features.html</a> for
more information on the set of transformations available for DataFrame
columns in Spark.
</p>
<p><code><a href="ft_bucketizer.html">ft_bucketizer</a></code>
</p>
<p>Other feature transformers: <code><a href="ft_binarizer.html">ft_binarizer</a></code>,
<code><a href="ft_bucketizer.html">ft_bucketizer</a></code>,
<code><a href="ft_chisq_selector.html">ft_chisq_selector</a></code>,
<code><a href="ft_count_vectorizer.html">ft_count_vectorizer</a></code>, <code><a href="ft_dct.html">ft_dct</a></code>,
<code><a href="ft_elementwise_product.html">ft_elementwise_product</a></code>,
<code><a href="ft_feature_hasher.html">ft_feature_hasher</a></code>,
<code><a href="ft_hashing_tf.html">ft_hashing_tf</a></code>, <code><a href="ft_idf.html">ft_idf</a></code>,
<code><a href="ft_imputer.html">ft_imputer</a></code>,
<code><a href="ft_index_to_string.html">ft_index_to_string</a></code>,
<code><a href="ft_interaction.html">ft_interaction</a></code>, <code><a href="ft_lsh.html">ft_lsh</a></code>,
<code><a href="ft_max_abs_scaler.html">ft_max_abs_scaler</a></code>,
<code><a href="ft_min_max_scaler.html">ft_min_max_scaler</a></code>, <code><a href="ft_ngram.html">ft_ngram</a></code>,
<code><a href="ft_normalizer.html">ft_normalizer</a></code>,
<code><a href="ft_one_hot_encoder.html">ft_one_hot_encoder</a></code>, <code><a href="ft_pca.html">ft_pca</a></code>,
<code><a href="ft_polynomial_expansion.html">ft_polynomial_expansion</a></code>,
<code><a href="ft_r_formula.html">ft_r_formula</a></code>,
<code><a href="ft_regex_tokenizer.html">ft_regex_tokenizer</a></code>,
<code><a href="sql-transformer.html">ft_sql_transformer</a></code>,
<code><a href="ft_standard_scaler.html">ft_standard_scaler</a></code>,
<code><a href="ft_stop_words_remover.html">ft_stop_words_remover</a></code>,
<code><a href="ft_string_indexer.html">ft_string_indexer</a></code>,
<code><a href="ft_tokenizer.html">ft_tokenizer</a></code>,
<code><a href="ft_vector_assembler.html">ft_vector_assembler</a></code>,
<code><a href="ft_vector_indexer.html">ft_vector_indexer</a></code>,
<code><a href="ft_vector_slicer.html">ft_vector_slicer</a></code>, <code><a href="ft_word2vec.html">ft_word2vec</a></code>
</p>

<hr /><div style="text-align: center;">[Package <em>sparklyr</em> version 0.8.2 <a href="00Index.html">Index</a>]</div>
</body></html>
